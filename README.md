# üçÑ Posso comer este cogumelo?

> MVP desenvolvido para a disciplina **Qualidade de Software, Seguran√ßa e Sistemas Inteligentes** da P√≥s-Gradua√ß√£o em Engenharia de Software ‚Äì **PUC-Rio**

## üìå Proposta

Este projeto √© uma solu√ß√£o de **Machine Learning** para um problema de **classifica√ß√£o**:

> **Dadas algumas caracter√≠sticas f√≠sicas de um cogumelo, podemos prever se ele √© comest√≠vel ou venenoso?**

A aplica√ß√£o possui uma interface simples para testar diferentes combina√ß√µes de atributos e avaliar a classifica√ß√£o do modelo treinado.

Notebook no Google Colab: https://colab.research.google.com/github/LucasRosas/MVP-2-Colab/blob/main/mushroom.ipynb

V√≠deo de apresenta√ß√£o no YouTube:

[![Apresenta√ß√£o de MVP - Posso comer esse cogumelo? | Lucas Ara√∫jo Rosas](https://img.youtube.com/vi/ZRZYooK0m2c/0.jpg)](https://www.youtube.com/watch?v=ZRZYooK0m2c)

---

## üóÇ Estrutura do Projeto

```

MVP-2-Colab/
‚îú‚îÄ‚îÄ backend/           # API Python com Flask para classifica√ß√£o dos cogumelos
|   ‚îî‚îÄ‚îÄ test           # Dados para teste e o teste do modelo.
‚îú‚îÄ‚îÄ frontend/          # Interface desenvolvida em Vue.js
‚îú‚îÄ‚îÄ mushroom/          # Dados originais utilizados no treinamento
‚îú‚îÄ‚îÄ mushroom.ipynb     # Notebook com o pipeline de treino e exporta√ß√£o do modelo
‚îî‚îÄ‚îÄ README.md          # Este arquivo

```

---

## üöÄ Instala√ß√£o

Clone o reposit√≥rio:

```bash
git clone https://github.com/LucasRosas/MVP-2-Colab.git
cd MVP-2-Colab
```

### üß† Backend (Flask)

```bash
cd backend
```

Crie e ative um ambiente virtual (recomendado):

```bash
# Instale o virtualenv se necess√°rio
pip install virtualenv

# Crie o ambiente
python -m venv .venv

# Ative o ambiente
# Windows:
.venv\Scripts\activate
# macOS/Linux:
source .venv/bin/activate
```

Instale as depend√™ncias:

```bash
pip install -r requirements.txt
```

Execute a API:

```bash
flask run --host 0.0.0.0 --port 5000
```

A documenta√ß√£o interativa estar√° dispon√≠vel em:
üìé [http://localhost:5000/openapi/swagger](http://localhost:5000/openapi/swagger)

#### üß™ Rota dispon√≠vel

```
GET /classifier
```

**Query Parameters:**

| Par√¢metro  | Tipo | Descri√ß√£o             | Exemplo |
| ---------- | ---- | --------------------- | ------- |
| capShape   | str  | Formato do chap√©u     | x       |
| capSurface | str  | Textura da superf√≠cie | y       |
| capColor   | str  | Cor do chap√©u         | w       |
| bruises    | str  | Presen√ßa de manchas   | t       |
| odor       | str  | Odor caracter√≠stico   | n       |

---

#### Rodar teste do modelo

Para rodar o teste do modelo basta executar

```bash
 pytest
```

![image](https://raw.githubusercontent.com/LucasRosas/MVP-2-Colab/refs/heads/main/frontend/public/test.jpg)

### üåø Frontend (Vue.js)

Em outro terminal, a partir da raiz do projeto:

```bash
cd frontend
```

Instale as depend√™ncias:

```bash
npm install
```

Execute a aplica√ß√£o:

```bash
npm run dev
```

Acesse a interface web em:
üåê [http://localhost:5173](http://localhost:5173)

---

## üî§ Classifica√ß√µes poss√≠veis

| Atributo        | C√≥digo | Descri√ß√£o              |
| --------------- | ------ | ---------------------- |
| **cap-shape**   | b      | bell (sino)            |
|                 | c      | conical (c√¥nico)       |
|                 | x      | convex (convexo)       |
|                 | f      | flat (plano)           |
|                 | k      | knobbed (protuberante) |
|                 | s      | sunken (afundado)      |
| **cap-surface** | f      | fibrous (fibrosa)      |
|                 | g      | grooves (sulcada)      |
|                 | y      | scaly (escamosa)       |
|                 | s      | smooth (lisa)          |
| **cap-color**   | n      | brown (marrom)         |
|                 | b      | buff (amarelado claro) |
|                 | c      | cinnamon (canela)      |
|                 | g      | gray (cinza)           |
|                 | r      | green (verde)          |
|                 | p      | pink (rosa)            |
|                 | u      | purple (roxo)          |
|                 | e      | red (vermelho)         |
|                 | w      | white (branco)         |
|                 | y      | yellow (amarelo)       |
| **bruises**     | t      | sim                    |
|                 | f      | n√£o                    |
| **odor**        | a      | almond (am√™ndoa)       |
|                 | l      | anise (anis)           |
|                 | c      | creosote (alcatr√£o)    |
|                 | y      | fishy (peixe)          |
|                 | f      | foul (f√©tido)          |
|                 | m      | musty (mofo)           |
|                 | n      | none (nenhum)          |
|                 | p      | pungent (picante)      |
|                 | s      | spicy (especiado)      |

---

## üß† Sobre o modelo

O modelo foi treinado com dados reais contendo caracter√≠sticas f√≠sicas e sensoriais de cogumelos, com a classifica√ß√£o final (`e` para comest√≠vel, `p` para venenoso). Foi utilizada uma abordagem de pr√©-processamento com `OneHotEncoder` e experimenta√ß√£o com diferentes algoritmos: `KNN`, `DecisionTree`, `NaiveBayes` e `SVM`.

## Conclus√£o

O presente trabalho teve como objetivo principal a constru√ß√£o de um modelo de machine learning para a resolu√ß√£o de um problema de classifica√ß√£o. Diferentemente do fluxo habitual, no qual primeiro se identifica um problema e depois se busca um conjunto de dados relevante, aqui o processo foi invertido: partiu-se da escolha de um dataset interessante e, a partir dele, foi elaborado o problema. A quest√£o proposta ("Ser√° que posso comer esse cogumelo?") extrapola o desafio t√©cnico e levanta tamb√©m quest√µes √©ticas sobre o uso respons√°vel da Intelig√™ncia Artificial, j√° que uma classifica√ß√£o incorreta pode causar desde uma leve intoxica√ß√£o alimentar at√© danos graves e irrevers√≠veis, incluindo a morte. Por esse motivo, foi adicionado √† aplica√ß√£o front-end um alerta expl√≠cito indicando que se trata de um exerc√≠cio acad√™mico, sem qualquer garantia quanto √† seguran√ßa do consumo. De fato, este projeto configura-se como um exerc√≠cio pr√°tico que permitiu explorar e compreender diversas etapas do fluxo de machine learning: sele√ß√£o de dados, pr√©-processamento, modelagem, otimiza√ß√£o e implementa√ß√£o.

Considerados os dilemas √©ticos, partimos para a constru√ß√£o do modelo. O dataset original, dispon√≠vel em https://archive.ics.uci.edu/dataset/73/mushroom, cont√©m 8.124 amostras hipot√©ticas, correspondentes a 23 esp√©cies de cogumelos classificadas como "comest√≠vel" ou "venenoso", descritas por meio de 22 atributos f√≠sicos. Para tornar o modelo mais acess√≠vel ao usu√°rio final, selecionaram-se apenas as cinco primeiras caracter√≠sticas para o treinamento.

Foram utilizados quatro algoritmos de classifica√ß√£o: KNN, Decision Tree, Naive Bayes e SVM. Todos apresentaram resultados bastante satisfat√≥rios, com acur√°cia acima de 98%. Como as vari√°veis eram todas categ√≥ricas, foi necess√°rio aplicar o OneHotEncoder no pr√©-processamento. Na etapa de otimiza√ß√£o, diferentemente do exemplo apresentado na aula 02, n√£o foram utilizados nem o StandardScaler nem o MinMaxScaler, sendo aplicado um conjunto pr√≥prio de par√¢metros para cada algoritmo no GridSearchCV.

### An√°lise de resultados do modelo:

Ao comparar a acur√°cia m√©dia da valida√ß√£o cruzada antes e depois da otimiza√ß√£o, observou-se uma varia√ß√£o muito pequena, em alguns casos at√© negativa:

| Modelo           | Acur√°cia CV Antes | Acur√°cia CV GridSearch | Varia√ß√£o |
| ---------------- | ----------------- | ---------------------- | -------- |
| **KNN**          | 0.9933            | 0.9937                 | +0.04%   |
| **DecisionTree** | 0.9930            | 0.9931                 | +0.01%   |
| **NaiveBayes**   | 0.9854            | 0.9851                 | -0.03%   |
| **SVM**          | 0.9944            | 0.9944                 | 0%       |

Nos testes com os dados n√£o utilizados no treinamento, o modelo Decision Tree apresentou o melhor score: 0,9971.

Como esperado, o Naive Bayes foi o modelo com as menores acur√°cias, ainda que bastante altas (cerca de 98,6%).

Em alguns testes iniciais, o modelo KNN alcan√ßou acur√°cia de 100% com os dados n√£o treinados ap√≥s otimiza√ß√£o. Isso provavelmente ocorreu devido √† aleatoriedade da divis√£o dos dados (mesmo utilizando diferentes seeds al√©m da 42), resultando em conjuntos mais facilmente separ√°veis.

O modelo SVM, que obteve a maior acur√°cia m√©dia nas valida√ß√µes cruzadas, foi o escolhido para exporta√ß√£o. Para isso, foi necess√°rio ativar a funcionalidade de c√°lculo de probabilidade, o que aumentou ligeiramente o tempo de treinamento.

Por fim, a aplica√ß√£o backend foi desenvolvida com um endpoint que permite utilizar o modelo para classifica√ß√£o, e o front-end foi constru√≠do e integrado √† API. Constatou-se que a escolha do modelo depende fortemente das caracter√≠sticas iniciais dos dados e do tratamento aplicado a eles. Algumas vezes, mesmo sem otimiza√ß√µes complexas, os modelos podem atingir resultados altamente satisfat√≥rios; outras vezes, ajustes mais refinados ser√£o necess√°rios. Al√©m disso, para cada tipo de dado, diferentes estrat√©gias de pr√©-processamento e modelagem podem ser recomendadas, sendo essencial a consulta √† documenta√ß√£o oficial e √† bibliografia especializada.
